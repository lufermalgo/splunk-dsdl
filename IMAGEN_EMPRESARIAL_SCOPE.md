# Scope: Imagen Docker Custom Empresarial

**Fecha**: 2025-01-31  
**Objetivo**: Definir componentes de imagen base empresarial para cientÃ­ficos de datos

---

## ðŸŽ¯ Objetivo

Crear imagen base que permita que los cientÃ­ficos de datos se concentren **SOLO** en desarrollar modelos, sin preocuparse por:
- âœ… TelemetrÃ­a/Monitoreo
- âœ… MÃ©tricas de negocio
- âœ… Preprocesamiento estÃ¡ndar
- âœ… ConexiÃ³n Splunk
- âœ… Logging estructurado

---

## ðŸ“¦ Componentes a Incluir

### 1. LibrerÃ­as Python Custom

**Archivo**: `requirements_files/empresa_custom.txt`

```text
# ML/DL Base
scikit-learn>=1.3.0
tensorflow>=2.15.0
torch>=2.0.0

# Series temporales
aeon>=0.5.0
statsmodels>=0.14.0
scipy>=1.11.0

# VisualizaciÃ³n
matplotlib>=3.8.0
seaborn>=0.13.0

# Utilidades
joblib>=1.3.0
pickle5>=0.0.11  # Si Python < 3.8
```

**Status**: Pendiente validar compatibilidad de versiones

---

### 2. Template Base Empresarial

**Archivo**: `notebooks_custom/template_empresa_base.ipynb`

**Funciones incluidas**:
- âœ… `init(df, param)` - InicializaciÃ³n estÃ¡ndar
- âœ… `fit(df, param)` - Con telemetrÃ­a automÃ¡tica
- âœ… `apply(df, param)` - Con mÃ©tricas automÃ¡ticas
- âœ… `summary(model)` - Metadata del modelo
- âœ… Stage data desde Splunk
- âœ… Preprocesamiento estÃ¡ndar (normalizaciÃ³n, etc.)

**CÃ©lulas**:
1. Imports con helpers empresariales
2. ConfiguraciÃ³n estÃ¡ndar (HEC, conexiÃ³n Splunk)
3. FunciÃ³n `init()`
4. FunciÃ³n `fit()` con logging
5. FunciÃ³n `apply()` con mÃ©tricas
6. FunciÃ³n `summary()`
7. CÃ©lulas de prueba (no exportables)

---

### 3. Helpers Empresariales

**Directorio**: `notebooks_custom/helpers/`

#### 3.1 `telemetry_helper.py`
- Logging HEC automÃ¡tico
- Funciones: `log_metrics()`, `log_training_step()`, `log_error()`
- ConfiguraciÃ³n automÃ¡tica desde variables de entorno

#### 3.2 `metrics_calculator.py`
- CÃ¡lculo de mÃ©tricas estÃ¡ndar
- Funciones: `calculate_all_metrics()`, `calculate_regression_metrics()`, `calculate_classification_metrics()`
- Retorna dict estandarizado

#### 3.3 `preprocessor.py`
- Preprocesamiento estÃ¡ndar
- Funciones: `standard_preprocessing()`, `handle_missing()`, `encode_categorical()`
- Scalers reutilizables

#### 3.4 `splunk_connector.py`
- Wrappers Splunk Search API
- Funciones: `get_data()`, `send_results()`, `validate_splunk_config()`

#### 3.5 `model_registry.py` (Opcional)
- Registro de modelos en MLflow
- Funciones: `log_model()`, `load_model_version()`, `compare_models()`

---

### 4. ConfiguraciÃ³n Empresarial

**Variables de entorno** (configurables en DSDL):
- HEC endpoint (automÃ¡tico desde DSDL)
- HEC token (automÃ¡tico)
- Splunk host (automÃ¡tico)
- Project/caso de uso (pasado por parÃ¡metro)
- Index destino para mÃ©tricas (configurable)

---

## ðŸ—ï¸ Estructura de Archivos

```
golden-cpu-empresa:5.2.2/
â”œâ”€â”€ requirements_files/
â”‚   â””â”€â”€ empresa_custom.txt          # âœ… LibrerÃ­as custom
â”œâ”€â”€ notebooks_custom/
â”‚   â”œâ”€â”€ template_empresa_base.ipynb  # âœ… Template base
â”‚   â””â”€â”€ helpers/
â”‚       â”œâ”€â”€ telemetry_helper.py      # âœ… Logging automÃ¡tico
â”‚       â”œâ”€â”€ metrics_calculator.py    # âœ… MÃ©tricas
â”‚       â”œâ”€â”€ preprocessor.py          # âœ… Preprocesamiento
â”‚       â”œâ”€â”€ splunk_connector.py      # âœ… ConexiÃ³n Splunk
â”‚       â””â”€â”€ model_registry.py        # âš ï¸ Opcional MLflow
â”œâ”€â”€ tag_mapping.csv
â”‚   â””â”€â”€ golden-cpu-empresa row       # âœ… Config build
â””â”€â”€ Dockerfile modificado
    â””â”€â”€ COPY notebooks_custom/       # âœ… Copiar helpers
```

---

## ðŸ“‹ Checklist de ImplementaciÃ³n

### Fase 1: PreparaciÃ³n (1 dÃ­a)
- [ ] Fork/clone del repositorio base DSDL
- [ ] Crear `empresa_custom.txt` con librerÃ­as
- [ ] Crear `helpers/` con archivos Python
- [ ] Crear `template_empresa_base.ipynb`
- [ ] Actualizar `tag_mapping.csv`

### Fase 2: Docker Configuration (1 dÃ­a)
- [ ] Modificar Dockerfile para copiar `notebooks_custom/`
- [ ] Validar estructura de paths
- [ ] Compilar requirements custom

### Fase 3: Build & Test (1 dÃ­a)
- [ ] Build local de imagen
- [ ] Ejecutar tests de helpers
- [ ] Validar template en JupyterLab
- [ ] Escanear vulnerabilidades

### Fase 4: Deploy Local Sandbox (0.5 dÃ­a)
- [ ] Push a registry local/Docker Hub
- [ ] Configurar en DSDL
- [ ] Test con dato real

### Fase 5: DocumentaciÃ³n (0.5 dÃ­a)
- [ ] Documentar uso del template
- [ ] GuÃ­a para cientÃ­ficos de datos
- [ ] Ejemplos de uso

---

## ðŸŽ¯ Resultado Esperado

**CientÃ­fico de datos**:
1. Abre `template_empresa_base.ipynb`
2. File â†’ Save As â†’ `SuNombre_Modelo_CasoUso_v1.ipynb`
3. Edita **SOLO** la funciÃ³n de modelo
4. Guarda
5. Usa desde SPL

**Sin tocar**:
- TelemetrÃ­a
- MÃ©tricas
- Preprocesamiento
- ConexiÃ³n Splunk
- Logging

---

## âš ï¸ Decisiones Pendientes

1. **LibrerÃ­as adicionales**: Â¿QuÃ© mÃ¡s incluir en `empresa_custom.txt`?
2. **MLflow**: Â¿Incluir helpers de MLflow o solo Splunk HEC?
3. **Index destino**: Â¿QuÃ© Ã­ndice usar para mÃ©tricas?
4. **Versioning**: Â¿Incluir helper de versionado automÃ¡tico?

---

## ðŸš€ PrÃ³ximo Paso

**Comenzar Fase 1**: Crear estructura de archivos y helpers base

