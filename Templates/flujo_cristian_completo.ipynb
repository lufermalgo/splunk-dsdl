{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ Flujo Completo de Cristian (Data Scientist)\n",
        "\n",
        "**Modelo**: Autoencoder para detecci√≥n de anomal√≠as\n",
        "\n",
        "**Flujo**: Splunk ‚Üí EDA ‚Üí Modelo ‚Üí Telemetr√≠a ‚Üí Producci√≥n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IMPORTS\n",
        "import sys\n",
        "sys.path.append(\"/srv/notebooks_custom/helpers\")\n",
        "\n",
        "# Helpers empresariales\n",
        "from telemetry_helper import log_metrics, log_training_step, log_error, log_prediction\n",
        "# Nota: calculate_all_metrics es para modelos supervisados (con target)\n",
        "# Autoencoder usa MSE/MAE directamente\n",
        "from metrics_calculator import calculate_all_metrics\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "print(\"‚úÖ Imports exitosos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FASE 1: Consultar datos de Splunk (exploraci√≥n)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Consultar datos de Splunk\n",
        "# Nota: Para desarrollo local usamos datos dummy\n",
        "# En producci√≥n, DSDL pasa los datos autom√°ticamente a fit()\n",
        "print(\"üîç Generando datos dummy para desarrollo...\")\n",
        "np.random.seed(42)\n",
        "df = pd.DataFrame(np.random.normal(0, 1, (1100, 5)), columns=[f'feature_{i}' for i in range(5)])\n",
        "print(f\"‚úÖ Datos dummy: {df.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FASE 2: Exploraci√≥n (EDA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üìä Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nüìà Stats:\")\n",
        "print(df.describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FASE 3: Funciones del Modelo (init, fit, apply, summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def init(param):\n",
        "    global model, scaler, n_features\n",
        "    print(f\"üîß Init: {param}\")\n",
        "    n_features = None\n",
        "    model = None\n",
        "    scaler = None\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fit(df, param):\n",
        "    global model, scaler, n_features\n",
        "    try:\n",
        "        print(f\"üìä Fit: {df.shape}\")\n",
        "        feature_cols = df.columns.tolist()\n",
        "        n_features = len(feature_cols)\n",
        "        X = df.values\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "        X_train, X_val = train_test_split(X_scaled, test_size=0.2, random_state=42)\n",
        "        \n",
        "        model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(32, activation='relu', input_shape=(n_features,)),\n",
        "            tf.keras.layers.Dense(16, activation='relu'),\n",
        "            tf.keras.layers.Dense(8, activation='relu'),\n",
        "            tf.keras.layers.Dense(16, activation='relu'),\n",
        "            tf.keras.layers.Dense(32, activation='relu'),\n",
        "            tf.keras.layers.Dense(n_features, activation='sigmoid')\n",
        "        ])\n",
        "        model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "        \n",
        "        epochs = param.get('epochs', 20)\n",
        "        history = model.fit(X_train, X_train, validation_data=(X_val, X_val), epochs=epochs, verbose=0)\n",
        "        \n",
        "        val_pred = model.predict(X_val, verbose=0)\n",
        "        mse = np.mean((X_val - val_pred) ** 2)\n",
        "        mae = np.mean(np.abs(X_val - val_pred))\n",
        "        \n",
        "        # TELEMETR√çA\n",
        "        log_metrics(model_name='cristian_demo', mae=mae, mse=mse)\n",
        "        log_training_step(model_name='cristian_demo', epoch=epochs, loss=mse)\n",
        "        \n",
        "        print(f\"üìä MSE: {mse:.4f}, MAE: {mae:.4f}\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        log_error(model_name='cristian_demo', error_message=str(e), error_type='fit')\n",
        "        raise e\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply(df):\n",
        "    global model, scaler\n",
        "    try:\n",
        "        if model is None:\n",
        "            raise ValueError(\"Modelo no entrenado\")\n",
        "        X = df.values\n",
        "        X_scaled = scaler.transform(X)\n",
        "        reconstructed = model.predict(X_scaled, verbose=0)\n",
        "        errors = np.mean((X_scaled - reconstructed) ** 2, axis=1)\n",
        "        log_prediction(model_name='cristian_demo', num_predictions=len(errors))\n",
        "        return errors\n",
        "    except Exception as e:\n",
        "        log_error(model_name='cristian_demo', error_message=str(e), error_type='apply')\n",
        "        raise e\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def summary(df):\n",
        "    if model is None:\n",
        "        return {\"status\": \"not initialized\"}\n",
        "    return {\"model_type\": \"Autoencoder\", \"trainable_parameters\": model.count_params()}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FASE 4: Probar modelo localmente\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test local\n",
        "param = {'epochs': 20, 'batch_size': 32}\n",
        "model = init(param)\n",
        "model = fit(df, param)\n",
        "predictions = apply(df)\n",
        "summary_result = summary(df)\n",
        "print(\"‚úÖ Test exitoso\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
